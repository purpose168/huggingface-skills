#!/usr/bin/env -S uv run
# /// script
# requires-python = ">=3.10"
# dependencies = [
#   "huggingface_hub>=0.20.0",
# ]
# ///
"""
Hugging Face æ•°æ®é›†ç®¡ç†å™¨

å¢å¼ºçš„æ•°æ®é›†åˆ›å»ºå’Œç®¡ç†å·¥å…·ï¼Œè®¾è®¡ä¸ºä¸ HF MCP æœåŠ¡å™¨ååŒå·¥ä½œã€‚æä¾›æ•°æ®é›†åˆ›å»ºã€é…ç½®å’Œå†…å®¹ç®¡ç†åŠŸèƒ½ï¼Œä¸ºå¯¹è¯å¼ AI è®­ç»ƒæ•°æ®è¿›è¡Œäº†ä¼˜åŒ–ã€‚

ç‰ˆæœ¬: 2.0.0

ä½¿ç”¨æ–¹æ³•:
    uv run dataset_manager.py init --repo_id username/dataset-name
    uv run dataset_manager.py quick_setup --repo_id username/dataset-name --template chat
    uv run dataset_manager.py add_rows --repo_id username/dataset-name --rows_json '[{"messages": [...]}]'
    uv run dataset_manager.py stats --repo_id username/dataset-name
    uv run dataset_manager.py list_templates
"""

import os
import json
import time
import argparse
from pathlib import Path
from typing import List, Dict, Any, Optional
from huggingface_hub import HfApi, create_repo
from huggingface_hub.utils import HfHubHTTPError

# é…ç½®
HF_TOKEN = os.environ.get("HF_TOKEN")
EXAMPLES_DIR = Path(__file__).parent.parent / "examples"


def init_dataset(repo_id, token=None, private=True):
    """
    åœ¨ Hugging Face Hub ä¸Šåˆå§‹åŒ–æ–°çš„æ•°æ®é›†ä»“åº“ã€‚
    """
    api = HfApi(token=token)
    try:
        create_repo(repo_id, repo_type="dataset", private=private, token=token)
        print(f"å·²åˆ›å»ºæ•°æ®é›†ä»“åº“: {repo_id}")
    except HfHubHTTPError as e:
        if "409" in str(e):
            print(f"ä»“åº“ {repo_id} å·²å­˜åœ¨ã€‚")
        else:
            raise e

    # å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºå¸¦æœ‰å…ƒæ•°æ®çš„åŸºæœ¬ README.md
    readme_content = f"""---
license: mit
---

# {repo_id.split("/")[-1]}

æ­¤æ•°æ®é›†æ˜¯ä½¿ç”¨ Claude æ•°æ®é›†æŠ€èƒ½åˆ›å»ºçš„ã€‚
"""
    try:
        api.upload_file(
            path_or_fileobj=readme_content.encode("utf-8"),
            path_in_repo="README.md",
            repo_id=repo_id,
            repo_type="dataset",
            commit_message="åˆå§‹åŒ–æ•°æ®é›† README",
        )
    except Exception as e:
        print(f"æ³¨æ„: README å¯èƒ½å·²å­˜åœ¨æˆ–æ›´æ–°å¤±è´¥: {e}")


def define_config(repo_id, system_prompt=None, token=None):
    """
    å®šä¹‰æ•°æ®é›†çš„é…ç½®ï¼ŒåŒ…æ‹¬ç³»ç»Ÿæç¤ºã€‚
    è¿™ä¼šå°† config.json æ–‡ä»¶ä¿å­˜åˆ°ä»“åº“ã€‚
    """
    api = HfApi(token=token)

    config_data = {"dataset_config": {"version": "1.0", "created_at": time.time()}}

    if system_prompt:
        config_data["system_prompt"] = system_prompt

    # ä¸Šä¼  config.json
    api.upload_file(
        path_or_fileobj=json.dumps(config_data, indent=2).encode("utf-8"),
        path_in_repo="config.json",
        repo_id=repo_id,
        repo_type="dataset",
        commit_message="æ›´æ–°æ•°æ®é›†é…ç½®",
    )
    print(f"å·²æ›´æ–° {repo_id} çš„é…ç½®")


def load_dataset_template(template_name: str) -> Dict[str, Any]:
    """ä»æ¨¡æ¿ç›®å½•åŠ è½½æ•°æ®é›†æ¨¡æ¿é…ç½®ã€‚"""
    template_path = EXAMPLES_DIR.parent / "templates" / f"{template_name}.json"
    if not template_path.exists():
        available_templates = [f.stem for f in (EXAMPLES_DIR.parent / "templates").glob("*.json")]
        print(f"âŒ æ¨¡æ¿ '{template_name}' æœªæ‰¾åˆ°ã€‚")
        print(f"å¯ç”¨æ¨¡æ¿: {', '.join(available_templates)}")
        return {}

    with open(template_path) as f:
        return json.load(f)


def validate_by_template(rows: List[Dict[str, Any]], template: Dict[str, Any]) -> bool:
    """æ ¹æ®æ¨¡æ¿æ¶æ„éªŒè¯æ•°æ®ã€‚"""
    if not template:
        return False

    schema = template.get("validation_schema", {})
    required_fields = set(schema.get("required_fields", []))
    recommended_fields = set(schema.get("recommended_fields", []))
    field_types = schema.get("field_types", {})

    for i, row in enumerate(rows):
        # æ£€æŸ¥å¿…å¡«å­—æ®µ
        if not all(field in row for field in required_fields):
            missing = required_fields - set(row.keys())
            print(f"è¡Œ {i}: ç¼ºå°‘å¿…å¡«å­—æ®µ: {missing}")
            return False

        # éªŒè¯å­—æ®µç±»å‹
        for field, expected_type in field_types.items():
            if field in row:
                if not _validate_field_type(row[field], expected_type, f"è¡Œ {i}, å­—æ®µ '{field}'"):
                    return False

        # æ¨¡æ¿ç‰¹å®šéªŒè¯
        if template["type"] == "chat":
            if not _validate_chat_format(row, i):
                return False
        elif template["type"] == "classification":
            if not _validate_classification_format(row, i):
                return False
        elif template["type"] == "tabular":
            if not _validate_tabular_format(row, i):
                return False

        # è­¦å‘Šç¼ºå°‘æ¨èå­—æ®µ
        missing_recommended = recommended_fields - set(row.keys())
        if missing_recommended:
            print(f"è¡Œ {i}: å»ºè®®åŒ…å«: {missing_recommended}")

    print(f"âœ“ å·²éªŒè¯ {len(rows)} ä¸ªç¤ºä¾‹ï¼Œç”¨äº {template['type']} æ•°æ®é›†")
    return True


def _validate_field_type(value: Any, expected_type: str, context: str) -> bool:
    """éªŒè¯å•ä¸ªå­—æ®µç±»å‹ã€‚"""
    if expected_type.startswith("enum:"):
        valid_values = expected_type[5:].split(",")
        if value not in valid_values:
            print(f"{context}: æ— æ•ˆå€¼ '{value}'ã€‚å¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€: {valid_values}")
            return False
    elif expected_type == "array" and not isinstance(value, list):
        print(f"{context}: æœŸæœ›æ•°ç»„ï¼Œå¾—åˆ° {type(value).__name__}")
        return False
    elif expected_type == "object" and not isinstance(value, dict):
        print(f"{context}: æœŸæœ›å¯¹è±¡ï¼Œå¾—åˆ° {type(value).__name__}")
        return False
    elif expected_type == "string" and not isinstance(value, str):
        print(f"{context}: æœŸæœ›å­—ç¬¦ä¸²ï¼Œå¾—åˆ° {type(value).__name__}")
        return False
    elif expected_type == "number" and not isinstance(value, (int, float)):
        print(f"{context}: æœŸæœ›æ•°å­—ï¼Œå¾—åˆ° {type(value).__name__}")
        return False

    return True


def _validate_chat_format(row: Dict[str, Any], row_index: int) -> bool:
    """éªŒè¯èŠå¤©ç‰¹å®šæ ¼å¼ã€‚"""
    messages = row.get("messages", [])
    if not isinstance(messages, list) or len(messages) == 0:
        print(f"è¡Œ {row_index}: 'messages' å¿…é¡»æ˜¯éç©ºåˆ—è¡¨")
        return False

    valid_roles = {"user", "assistant", "tool", "system"}
    for j, msg in enumerate(messages):
        if not isinstance(msg, dict):
            print(f"è¡Œ {row_index}, æ¶ˆæ¯ {j}: å¿…é¡»æ˜¯å¯¹è±¡")
            return False
        if "role" not in msg or msg["role"] not in valid_roles:
            print(f"è¡Œ {row_index}, æ¶ˆæ¯ {j}: æ— æ•ˆè§’è‰²ã€‚ä½¿ç”¨: {valid_roles}")
            return False
        if "content" not in msg:
            print(f"è¡Œ {row_index}, æ¶ˆæ¯ {j}: ç¼ºå°‘ 'content' å­—æ®µ")
            return False

    return True


def _validate_classification_format(row: Dict[str, Any], row_index: int) -> bool:
    """éªŒè¯åˆ†ç±»ç‰¹å®šæ ¼å¼ã€‚"""
    if "text" not in row:
        print(f"è¡Œ {row_index}: ç¼ºå°‘ 'text' å­—æ®µ")
        return False
    if "label" not in row:
        print(f"è¡Œ {row_index}: ç¼ºå°‘ 'label' å­—æ®µ")
        return False

    return True


def _validate_tabular_format(row: Dict[str, Any], row_index: int) -> bool:
    """éªŒè¯è¡¨æ ¼ç‰¹å®šæ ¼å¼ã€‚"""
    if "data" not in row:
        print(f"è¡Œ {row_index}: ç¼ºå°‘ 'data' å­—æ®µ")
        return False
    if "columns" not in row:
        print(f"è¡Œ {row_index}: ç¼ºå°‘ 'columns' å­—æ®µ")
        return False

    data = row["data"]
    columns = row["columns"]

    if not isinstance(data, list):
        print(f"è¡Œ {row_index}: 'data' å¿…é¡»æ˜¯æ•°ç»„")
        return False
    if not isinstance(columns, list):
        print(f"è¡Œ {row_index}: 'columns' å¿…é¡»æ˜¯æ•°ç»„")
        return False

    return True


def validate_training_data(rows: List[Dict[str, Any]], template_name: str = "chat") -> bool:
    """
    æ ¹æ®æ¨¡æ¿éªŒè¯è®­ç»ƒæ•°æ®ç»“æ„ã€‚
    æ”¯æŒå¤šç§æ•°æ®é›†ç±»å‹ï¼Œå…·æœ‰é€‚å½“çš„éªŒè¯ã€‚
    """
    template = load_dataset_template(template_name)
    if not template:
        print(f"âŒ æ— æ³•åŠ è½½æ¨¡æ¿ '{template_name}'ï¼Œå›é€€åˆ°åŸºæœ¬éªŒè¯")
        return _basic_validation(rows)

    return validate_by_template(rows, template)


def _basic_validation(rows: List[Dict[str, Any]]) -> bool:
    """å½“æ²¡æœ‰æ¨¡æ¿å¯ç”¨æ—¶çš„åŸºæœ¬éªŒè¯ã€‚"""
    for i, row in enumerate(rows):
        if not isinstance(row, dict):
            print(f"è¡Œ {i}: å¿…é¡»æ˜¯å­—å…¸/å¯¹è±¡")
            return False
    print(f"âœ“ åŸºæœ¬éªŒè¯é€šè¿‡ï¼Œå…± {len(rows)} è¡Œ")
    return True


def add_rows(
    repo_id: str,
    rows: List[Dict[str, Any]],
    split: str = "train",
    validate: bool = True,
    template: str = "chat",
    token: Optional[str] = None,
) -> None:
    """
    é€šè¿‡ä¸Šä¼ æ–°çš„æ•°æ®å—æ¥æµå¼æ›´æ–°æ•°æ®é›†ã€‚
    å¢å¼ºäº†å¯¹å¤šç§æ•°æ®é›†ç±»å‹çš„éªŒè¯ã€‚

    å‚æ•°:
        repo_id: ä»“åº“æ ‡è¯†ç¬¦ (username/dataset-name)
        rows: è®­ç»ƒç¤ºä¾‹åˆ—è¡¨
        split: æ•°æ®é›†æ‹†åˆ†åç§° (train, test, validation)
        validate: æ˜¯å¦åœ¨ä¸Šä¼ å‰éªŒè¯æ•°æ®ç»“æ„
        template: æ•°æ®é›†æ¨¡æ¿ç±»å‹ (chat, classification, qa, completion, tabular, custom)
        token: HuggingFace API ä»¤ç‰Œ
    """
    api = HfApi(token=token)

    if not rows:
        print("æ²¡æœ‰è¦æ·»åŠ çš„è¡Œã€‚")
        return

    # éªŒè¯è®­ç»ƒæ•°æ®ç»“æ„
    if validate and not validate_training_data(rows, template):
        print("âŒ éªŒè¯å¤±è´¥ã€‚ä½¿ç”¨ --no-validate è·³è¿‡éªŒè¯ã€‚")
        return

    # åˆ›å»ºä»¥æ¢è¡Œç¬¦åˆ†éš”çš„ JSON å­—ç¬¦ä¸²
    jsonl_content = "\n".join(json.dumps(row) for row in rows)

    # ä¸ºæ­¤æ•°æ®å—ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
    timestamp = int(time.time() * 1000)
    filename = f"data/{split}-{timestamp}.jsonl"

    try:
        api.upload_file(
            path_or_fileobj=jsonl_content.encode("utf-8"),
            path_in_repo=filename,
            repo_id=repo_id,
            repo_type="dataset",
            commit_message=f"å‘ {split} æ‹†åˆ†æ·»åŠ  {len(rows)} è¡Œ",
        )
        print(f"âœ… å·²å‘ {repo_id} æ·»åŠ  {len(rows)} è¡Œ (æ‹†åˆ†: {split})")
    except Exception as e:
        print(f"âŒ ä¸Šä¼ å¤±è´¥: {e}")
        return


def load_template(template_name: str = "system_prompt_template.txt") -> str:
    """ä»ç¤ºä¾‹ç›®å½•åŠ è½½æ¨¡æ¿æ–‡ä»¶ã€‚"""
    template_path = EXAMPLES_DIR / template_name
    if template_path.exists():
        return template_path.read_text()
    else:
        print(f"âš ï¸ æ¨¡æ¿ {template_name} åœ¨ {template_path} æœªæ‰¾åˆ°")
        return ""


def quick_setup(repo_id: str, template_type: str = "chat", token: Optional[str] = None) -> None:
    """
    ä½¿ç”¨æ¨¡æ¿å¿«é€Ÿè®¾ç½®ä¸åŒçš„æ•°æ®é›†ç±»å‹ã€‚

    å‚æ•°:
        repo_id: ä»“åº“æ ‡è¯†ç¬¦
        template_type: æ•°æ®é›†æ¨¡æ¿ (chat, classification, qa, completion, tabular, custom)
        token: HuggingFace API ä»¤ç‰Œ
    """
    print(f"ğŸš€ ä½¿ç”¨ '{template_type}' æ¨¡æ¿å¿«é€Ÿè®¾ç½® {repo_id}...")

    # åŠ è½½æ¨¡æ¿é…ç½®
    template_config = load_dataset_template(template_type)
    if not template_config:
        print(f"âŒ æ— æ³•åŠ è½½æ¨¡æ¿ '{template_type}'ã€‚è®¾ç½®å·²å–æ¶ˆã€‚")
        return

    # åˆå§‹åŒ–ä»“åº“
    init_dataset(repo_id, token=token, private=True)

    # ä½¿ç”¨æ¨¡æ¿ç³»ç»Ÿæç¤ºé…ç½®
    system_prompt = template_config.get("system_prompt", "")
    if system_prompt:
        define_config(repo_id, system_prompt=system_prompt, token=token)

    # æ·»åŠ æ¨¡æ¿ç¤ºä¾‹
    examples = template_config.get("examples", [])
    if examples:
        add_rows(repo_id, examples, template=template_type, token=token)
        print(f"âœ… ä»æ¨¡æ¿æ·»åŠ äº† {len(examples)} ä¸ªç¤ºä¾‹")

    print(f"âœ… å·²å®Œæˆ {repo_id} çš„å¿«é€Ÿè®¾ç½®")
    print(f"ğŸ“Š æ•°æ®é›†ç±»å‹: {template_config.get('description', 'æ— æè¿°')}")

    # æ˜¾ç¤ºåç»­æ­¥éª¤
    print(f"\nğŸ“‹ åç»­æ­¥éª¤:")
    print(
        f"1. æ·»åŠ æ›´å¤šæ•°æ®: python scripts/dataset_manager.py add_rows --repo_id {repo_id} --template {template_type} --rows_json 'your_data.json'"
    )
    print(f"2. æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯: python scripts/dataset_manager.py stats --repo_id {repo_id}")
    print(f"3. æµè§ˆ: https://huggingface.co/datasets/{repo_id}")


def show_stats(repo_id: str, token: Optional[str] = None) -> None:
    """æ˜¾ç¤ºæ•°æ®é›†çš„ç»Ÿè®¡ä¿¡æ¯ã€‚"""
    api = HfApi(token=token)

    try:
        # è·å–ä»“åº“ä¿¡æ¯
        repo_info = api.repo_info(repo_id, repo_type="dataset")
        print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯: {repo_id}")
        print(f"åˆ›å»ºæ—¶é—´: {repo_info.created_at}")
        print(f"æ›´æ–°æ—¶é—´: {repo_info.last_modified}")
        print(f"ç§æœ‰: {repo_info.private}")

        # åˆ—å‡ºæ–‡ä»¶
        files = api.list_repo_files(repo_id, repo_type="dataset")
        data_files = [f for f in files if f.startswith("data/")]
        print(f"æ•°æ®æ–‡ä»¶: {len(data_files)}")

        if "config.json" in files:
            print("âœ… é…ç½®å­˜åœ¨")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°é…ç½®")

    except Exception as e:
        print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")


def list_available_templates() -> None:
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ•°æ®é›†æ¨¡æ¿åŠå…¶æè¿°ã€‚"""
    templates_dir = EXAMPLES_DIR.parent / "templates"

    if not templates_dir.exists():
        print("âŒ æœªæ‰¾åˆ°æ¨¡æ¿ç›®å½•")
        return

    print("\nğŸ“‹ å¯ç”¨æ•°æ®é›†æ¨¡æ¿:")
    print("=" * 50)

    for template_file in templates_dir.glob("*.json"):
        try:
            with open(template_file) as f:
                template = json.load(f)

            name = template_file.stem
            desc = template.get("description", "æ— å¯ç”¨æè¿°")
            template_type = template.get("type", name)

            print(f"\nğŸ·ï¸  {name}")
            print(f"   ç±»å‹: {template_type}")
            print(f"   æè¿°: {desc}")

            # æ˜¾ç¤ºå¿…å¡«å­—æ®µ
            schema = template.get("validation_schema", {})
            required = schema.get("required_fields", [])
            if required:
                print(f"   å¿…å¡«å­—æ®µ: {', '.join(required)}")

        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡æ¿ {template_file.name} æ—¶å‡ºé”™: {e}")

    print(
        f"\nğŸ’¡ ä½¿ç”¨æ–¹æ³•: python scripts/dataset_manager.py quick_setup --repo_id your-username/dataset-name --template TEMPLATE_NAME"
    )
    print(f"ğŸ“š ç¤ºä¾‹æ¨¡æ¿ç›®å½•: {templates_dir}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Hugging Face æ•°æ®é›†ç®¡ç†å™¨")
    subparsers = parser.add_subparsers(dest="command", required=True)

    # åˆå§‹åŒ–å‘½ä»¤
    init_parser = subparsers.add_parser("init", help="åˆå§‹åŒ–æ–°æ•°æ®é›†")
    init_parser.add_argument("--repo_id", required=True, help="ä»“åº“ ID (user/repo_name)")
    init_parser.add_argument("--private", action="store_true", help="å°†ä»“åº“è®¾ä¸ºç§æœ‰")

    # é…ç½®å‘½ä»¤
    config_parser = subparsers.add_parser("config", help="è®¾ç½®æ•°æ®é›†é…ç½®")
    config_parser.add_argument("--repo_id", required=True, help="ä»“åº“ ID")
    config_parser.add_argument("--system_prompt", help="å­˜å‚¨åœ¨é…ç½®ä¸­çš„ç³»ç»Ÿæç¤º")

    # æ·»åŠ è¡Œå‘½ä»¤
    add_parser = subparsers.add_parser("add_rows", help="å‘æ•°æ®é›†æ·»åŠ è¡Œ")
    add_parser.add_argument("--repo_id", required=True, help="ä»“åº“ ID")
    add_parser.add_argument("--split", default="train", help="æ•°æ®é›†æ‹†åˆ† (ä¾‹å¦‚: train, test)")
    add_parser.add_argument(
        "--template",
        default="chat",
        choices=[
            "chat",
            "classification",
            "qa",
            "completion",
            "tabular",
            "custom",
        ],
        help="ç”¨äºéªŒè¯çš„æ•°æ®é›†æ¨¡æ¿ç±»å‹",
    )
    add_parser.add_argument(
        "--rows_json",
        required=True,
        help="åŒ…å«è¡Œåˆ—è¡¨çš„ JSON å­—ç¬¦ä¸²",
    )
    add_parser.add_argument(
        "--no-validate",
        dest="validate",
        action="store_false",
        help="è·³è¿‡æ•°æ®éªŒè¯",
    )

    # å¿«é€Ÿè®¾ç½®å‘½ä»¤
    setup_parser = subparsers.add_parser("quick_setup", help="ä½¿ç”¨æ¨¡æ¿å¿«é€Ÿè®¾ç½®")
    setup_parser.add_argument("--repo_id", required=True, help="ä»“åº“ ID")
    setup_parser.add_argument(
        "--template",
        default="chat",
        choices=[
            "chat",
            "classification",
            "qa",
            "completion",
            "tabular",
            "custom",
        ],
        help="æ•°æ®é›†æ¨¡æ¿ç±»å‹",
    )

    # ç»Ÿè®¡å‘½ä»¤
    stats_parser = subparsers.add_parser("stats", help="æ˜¾ç¤ºæ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯")
    stats_parser.add_argument("--repo_id", required=True, help="ä»“åº“ ID")

    # åˆ—å‡ºæ¨¡æ¿å‘½ä»¤
    templates_parser = subparsers.add_parser("list_templates", help="åˆ—å‡ºå¯ç”¨çš„æ•°æ®é›†æ¨¡æ¿")

    args = parser.parse_args()

    token = HF_TOKEN
    if not token:
        print("è­¦å‘Š: æœªè®¾ç½® HF_TOKEN ç¯å¢ƒå˜é‡ã€‚")

    if args.command == "init":
        init_dataset(args.repo_id, token=token, private=args.private)
    elif args.command == "config":
        define_config(args.repo_id, system_prompt=args.system_prompt, token=token)
    elif args.command == "add_rows":
        try:
            rows = json.loads(args.rows_json)
            if not isinstance(rows, list):
                raise ValueError("rows_json å¿…é¡»æ˜¯å¯¹è±¡çš„ JSON åˆ—è¡¨")
            add_rows(
                args.repo_id,
                rows,
                split=args.split,
                template=args.template,
                validate=args.validate,
                token=token,
            )
        except json.JSONDecodeError:
            print("é”™è¯¯: ä¸º --rows_json æä¾›çš„ JSON æ— æ•ˆ")
    elif args.command == "quick_setup":
        quick_setup(args.repo_id, template_type=args.template, token=token)
    elif args.command == "stats":
        show_stats(args.repo_id, token=token)
    elif args.command == "list_templates":
        list_available_templates()
