# å°†è®­ç»ƒç»“æœä¿å­˜åˆ° Hugging Face Hub

**âš ï¸ é‡è¦æç¤º:** è®­ç»ƒç¯å¢ƒæ˜¯ä¸´æ—¶çš„ã€‚é™¤éæ¨é€åˆ° Hub,å¦åˆ™ä½œä¸šå®Œæˆæ—¶æ‰€æœ‰ç»“æœéƒ½ä¼šä¸¢å¤±ã€‚

## ä¸ºä»€ä¹ˆéœ€è¦æ¨é€åˆ° Hub

åœ¨ Hugging Face Jobs ä¸Šè¿è¡Œæ—¶:
- ç¯å¢ƒæ˜¯ä¸´æ—¶çš„
- ä½œä¸šå®Œæˆæ—¶æ‰€æœ‰æ–‡ä»¶éƒ½ä¼šè¢«åˆ é™¤
- æ²¡æœ‰æœ¬åœ°ç£ç›˜æŒä¹…åŒ–
- ä½œä¸šç»“æŸåæ— æ³•è®¿é—®ç»“æœ

**å¦‚æœä¸æ¨é€åˆ° Hub,è®­ç»ƒå°†å®Œå…¨ç™½è´¹ã€‚**

## å¿…éœ€é…ç½®

### 1. è®­ç»ƒé…ç½®

åœ¨æ‚¨çš„ SFTConfig æˆ–è®­ç»ƒå™¨é…ç½®ä¸­:

```python
SFTConfig(
    push_to_hub=True,                    # å¯ç”¨ Hub æ¨é€
    hub_model_id="username/model-name",   # ç›®æ ‡ä»“åº“
)
```

### 2. ä½œä¸šé…ç½®

æäº¤ä½œä¸šæ—¶:

```python
hf_jobs("uv", {
    "script": "train.py",
    "secrets": {"HF_TOKEN": "$HF_TOKEN"}  # æä¾›èº«ä»½éªŒè¯
})
```

**`$HF_TOKEN` å ä½ç¬¦ä¼šè‡ªåŠ¨æ›¿æ¢ä¸ºæ‚¨çš„ Hugging Face ä»¤ç‰Œã€‚**

## å®Œæ•´ç¤ºä¾‹

```python
# train.py
# /// script
# dependencies = ["trl"]
# ///

from trl import SFTTrainer, SFTConfig
from datasets import load_dataset

dataset = load_dataset("trl-lib/Capybara", split="train")

# é…ç½® Hub æ¨é€
config = SFTConfig(
    output_dir="my-model",
    num_train_epochs=3,

    # âœ… å…³é”®:Hub æ¨é€é…ç½®
    push_to_hub=True,
    hub_model_id="myusername/my-trained-model",

    # å¯é€‰:æ¨é€ç­–ç•¥
    push_to_hub_model_id="myusername/my-trained-model",
    push_to_hub_organization=None,
    push_to_hub_token=None,  # ä½¿ç”¨ç¯å¢ƒä»¤ç‰Œ
)

trainer = SFTTrainer(
    model="Qwen/Qwen2.5-0.5B",
    train_dataset=dataset,
    args=config,
)

trainer.train()

# âœ… æ¨é€æœ€ç»ˆæ¨¡å‹
trainer.push_to_hub()

print("âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: https://huggingface.co/myusername/my-trained-model")
```

**ä½¿ç”¨èº«ä»½éªŒè¯æäº¤:**

```python
hf_jobs("uv", {
    "script": "train.py",
    "flavor": "a10g-large",
    "timeout": "2h",
    "secrets": {"HF_TOKEN": "$HF_TOKEN"}  # âœ… å¿…éœ€!
})
```

## ä¿å­˜çš„å†…å®¹

å½“ `push_to_hub=True` æ—¶:

1. **æ¨¡å‹æƒé‡** - æœ€ç»ˆè®­ç»ƒçš„å‚æ•°
2. **åˆ†è¯å™¨** - å…³è”çš„åˆ†è¯å™¨
3. **é…ç½®** - æ¨¡å‹é…ç½® (config.json)
4. **è®­ç»ƒå‚æ•°** - ä½¿ç”¨çš„è¶…å‚æ•°
5. **æ¨¡å‹å¡ç‰‡** - è‡ªåŠ¨ç”Ÿæˆçš„æ–‡æ¡£
6. **æ£€æŸ¥ç‚¹** - å¦‚æœå¯ç”¨äº† `save_strategy="steps"`

## æ£€æŸ¥ç‚¹ä¿å­˜

åœ¨è®­ç»ƒæœŸé—´ä¿å­˜ä¸­é—´æ£€æŸ¥ç‚¹:

```python
SFTConfig(
    output_dir="my-model",
    push_to_hub=True,
    hub_model_id="username/my-model",

    # æ£€æŸ¥ç‚¹é…ç½®
    save_strategy="steps",
    save_steps=100,              # æ¯ 100 æ­¥ä¿å­˜ä¸€æ¬¡
    save_total_limit=3,          # ä»…ä¿ç•™æœ€å 3 ä¸ªæ£€æŸ¥ç‚¹
)
```

**ä¼˜åŠ¿:**
- å¦‚æœä½œä¸šå¤±è´¥,å¯ä»¥æ¢å¤è®­ç»ƒ
- æ¯”è¾ƒæ£€æŸ¥ç‚¹æ€§èƒ½
- ä½¿ç”¨ä¸­é—´æ¨¡å‹

**æ£€æŸ¥ç‚¹æ¨é€åˆ°:** `username/my-model` (åŒä¸€ä»“åº“)

## èº«ä»½éªŒè¯æ–¹æ³•

### æ–¹æ³• 1: è‡ªåŠ¨ä»¤ç‰Œ (æ¨è)

```python
"secrets": {"HF_TOKEN": "$HF_TOKEN"}
```

è‡ªåŠ¨ä½¿ç”¨æ‚¨ç™»å½•çš„ Hugging Face ä»¤ç‰Œã€‚

### æ–¹æ³• 2: æ˜¾å¼ä»¤ç‰Œ

```python
"secrets": {"HF_TOKEN": "hf_abc123..."}
```

æ˜¾å¼æä¾›ä»¤ç‰Œ (å‡ºäºå®‰å…¨è€ƒè™‘ä¸æ¨è)ã€‚

### æ–¹æ³• 3: ç¯å¢ƒå˜é‡

```python
"env": {"HF_TOKEN": "hf_abc123..."}
```

ä½œä¸ºå¸¸è§„ç¯å¢ƒå˜é‡ä¼ é€’ (ä¸å¦‚ secrets å®‰å…¨)ã€‚

**å‡ºäºå®‰å…¨å’Œä¾¿åˆ©è€ƒè™‘,å§‹ç»ˆä¼˜å…ˆä½¿ç”¨æ–¹æ³• 1ã€‚**

## éªŒè¯æ¸…å•

æäº¤ä»»ä½•è®­ç»ƒä½œä¸šä¹‹å‰,è¯·éªŒè¯:

- [ ] è®­ç»ƒé…ç½®ä¸­æœ‰ `push_to_hub=True`
- [ ] æŒ‡å®šäº† `hub_model_id` (æ ¼å¼: `username/model-name`)
- [ ] ä½œä¸šé…ç½®ä¸­æœ‰ `secrets={"HF_TOKEN": "$HF_TOKEN"}`
- [ ] ä»“åº“åç§°ä¸ä¸ç°æœ‰ä»“åº“å†²çª
- [ ] æ‚¨å¯¹ç›®æ ‡å‘½åç©ºé—´æœ‰å†™å…¥æƒé™

## ä»“åº“è®¾ç½®

### è‡ªåŠ¨åˆ›å»º

å¦‚æœä»“åº“ä¸å­˜åœ¨,é¦–æ¬¡æ¨é€æ—¶ä¼šè‡ªåŠ¨åˆ›å»ºã€‚

### æ‰‹åŠ¨åˆ›å»º

åœ¨è®­ç»ƒå‰åˆ›å»ºä»“åº“:

```python
from huggingface_hub import HfApi

api = HfApi()
api.create_repo(
    repo_id="username/model-name",
    repo_type="model",
    private=False,  # æˆ– True è¡¨ç¤ºç§æœ‰ä»“åº“
)
```

### ä»“åº“å‘½å

**æœ‰æ•ˆåç§°:**
- `username/my-model`
- `username/model-name`
- `organization/model-name`

**æ— æ•ˆåç§°:**
- `model-name` (ç¼ºå°‘ç”¨æˆ·å)
- `username/model name` (ä¸å…è®¸ç©ºæ ¼)
- `username/MODEL` (ä¸é¼“åŠ±ä½¿ç”¨å¤§å†™)

## æ•…éšœæ’é™¤

### é”™è¯¯: 401 æœªæˆæƒ

**åŸå› :** æœªæä¾› HF_TOKEN æˆ–ä»¤ç‰Œæ— æ•ˆ

**è§£å†³æ–¹æ¡ˆ:**
1. éªŒè¯ä½œä¸šé…ç½®ä¸­æœ‰ `secrets={"HF_TOKEN": "$HF_TOKEN"}`
2. æ£€æŸ¥æ‚¨æ˜¯å¦å·²ç™»å½•: `huggingface-cli whoami`
3. é‡æ–°ç™»å½•: `huggingface-cli login`

### é”™è¯¯: 403 ç¦æ­¢è®¿é—®

**åŸå› :** æ²¡æœ‰ä»“åº“çš„å†™å…¥æƒé™

**è§£å†³æ–¹æ¡ˆ:**
1. æ£€æŸ¥ä»“åº“å‘½åç©ºé—´æ˜¯å¦ä¸æ‚¨çš„ç”¨æˆ·ååŒ¹é…
2. éªŒè¯æ‚¨æ˜¯ç»„ç»‡æˆå‘˜ (å¦‚æœä½¿ç”¨ç»„ç»‡å‘½åç©ºé—´)
3. æ£€æŸ¥ä»“åº“æ˜¯å¦ä¸ºç§æœ‰ (å¦‚æœè®¿é—®ç»„ç»‡ä»“åº“)

### é”™è¯¯: ä»“åº“æœªæ‰¾åˆ°

**åŸå› :** ä»“åº“ä¸å­˜åœ¨ä¸”è‡ªåŠ¨åˆ›å»ºå¤±è´¥

**è§£å†³æ–¹æ¡ˆ:**
1. å…ˆæ‰‹åŠ¨åˆ›å»ºä»“åº“
2. æ£€æŸ¥ä»“åº“åç§°æ ¼å¼
3. éªŒè¯å‘½åç©ºé—´å­˜åœ¨

### é”™è¯¯: è®­ç»ƒæœŸé—´æ¨é€å¤±è´¥

**åŸå› :** ç½‘ç»œé—®é¢˜æˆ– Hub ä¸å¯ç”¨

**è§£å†³æ–¹æ¡ˆ:**
1. è®­ç»ƒç»§ç»­ä½†æœ€ç»ˆæ¨é€å¤±è´¥
2. æ£€æŸ¥ç‚¹å¯èƒ½å·²ä¿å­˜
3. ä½œä¸šå®Œæˆåæ‰‹åŠ¨é‡æ–°è¿è¡Œæ¨é€

### é—®é¢˜: æ¨¡å‹å·²ä¿å­˜ä½†ä¸å¯è§

**å¯èƒ½åŸå› :**
1. ä»“åº“æ˜¯ç§æœ‰çš„ - æ£€æŸ¥ https://huggingface.co/username
2. å‘½åç©ºé—´é”™è¯¯ - éªŒè¯ `hub_model_id` ä¸ç™»å½•ä¿¡æ¯åŒ¹é…
3. æ¨é€ä»åœ¨è¿›è¡Œä¸­ - ç­‰å¾…å‡ åˆ†é’Ÿ

## è®­ç»ƒåæ‰‹åŠ¨æ¨é€

å¦‚æœè®­ç»ƒå®Œæˆä½†æ¨é€å¤±è´¥,è¯·æ‰‹åŠ¨æ¨é€:

```python
from transformers import AutoModel, AutoTokenizer

# ä»æœ¬åœ°æ£€æŸ¥ç‚¹åŠ è½½
model = AutoModel.from_pretrained("./output_dir")
tokenizer = AutoTokenizer.from_pretrained("./output_dir")

# æ¨é€åˆ° Hub
model.push_to_hub("username/model-name", token="hf_abc123...")
tokenizer.push_to_hub("username/model-name", token="hf_abc123...")
```

**æ³¨æ„:** ä»…åœ¨ä½œä¸šæœªå®Œæˆ (æ–‡ä»¶ä»å­˜åœ¨) æ—¶æ‰å¯èƒ½ã€‚

## æœ€ä½³å®è·µ

1. **å§‹ç»ˆå¯ç”¨ `push_to_hub=True`**
2. **ä½¿ç”¨æ£€æŸ¥ç‚¹ä¿å­˜** è¿›è¡Œé•¿æ—¶é—´è®­ç»ƒ
3. **åœ¨ä½œä¸šå®Œæˆå‰éªŒè¯ Hub æ¨é€** åœ¨æ—¥å¿—ä¸­
4. **è®¾ç½®é€‚å½“çš„ `save_total_limit`** ä»¥é¿å…è¿‡å¤šçš„æ£€æŸ¥ç‚¹
5. **ä½¿ç”¨æè¿°æ€§çš„ä»“åº“åç§°** (ä¾‹å¦‚, `qwen-capybara-sft` è€Œä¸æ˜¯ `model1`)
6. **æ·»åŠ æ¨¡å‹å¡ç‰‡** åŒ…å«è®­ç»ƒè¯¦ç»†ä¿¡æ¯
7. **æ ‡è®°æ¨¡å‹** ä½¿ç”¨ç›¸å…³æ ‡ç­¾ (ä¾‹å¦‚, `text-generation`, `fine-tuned`)

## ç›‘æ§æ¨é€è¿›åº¦

æ£€æŸ¥æ—¥å¿—ä»¥è·å–æ¨é€è¿›åº¦:

```python
hf_jobs("logs", {"job_id": "your-job-id"})
```

**æŸ¥æ‰¾:**
```
Pushing model to username/model-name...
Upload file pytorch_model.bin: 100%
âœ… Model pushed successfully
```

## ç¤ºä¾‹: å®Œæ•´ç”Ÿäº§ç¯å¢ƒè®¾ç½®

```python
# production_train.py
# /// script
# dependencies = ["trl>=0.12.0", "peft>=0.7.0"]
# ///

from datasets import load_dataset
from peft import LoraConfig
from trl import SFTTrainer, SFTConfig
import os

# éªŒè¯ä»¤ç‰Œå¯ç”¨
assert "HF_TOKEN" in os.environ, "HF_TOKEN not found in environment!"

# åŠ è½½æ•°æ®é›†
dataset = load_dataset("trl-lib/Capybara", split="train")
print(f"âœ… Dataset loaded: {len(dataset)} examples")

# é…ç½®å…¨é¢çš„ Hub è®¾ç½®
config = SFTConfig(
    output_dir="qwen-capybara-sft",

    # Hub é…ç½®
    push_to_hub=True,
    hub_model_id="myusername/qwen-capybara-sft",
    hub_strategy="checkpoint",  # æ¨é€æ£€æŸ¥ç‚¹

    # æ£€æŸ¥ç‚¹é…ç½®
    save_strategy="steps",
    save_steps=100,
    save_total_limit=3,

    # è®­ç»ƒè®¾ç½®
    num_train_epochs=3,
    per_device_train_batch_size=4,

    # æ—¥å¿—è®°å½•
    logging_steps=10,
    logging_first_step=True,
)

# ä½¿ç”¨ LoRA è®­ç»ƒ
trainer = SFTTrainer(
    model="Qwen/Qwen2.5-0.5B",
    train_dataset=dataset,
    args=config,
    peft_config=LoraConfig(r=16, lora_alpha=32),
)

print("ğŸš€ Starting training...")
trainer.train()

print("ğŸ’¾ Pushing final model to Hub...")
trainer.push_to_hub()

print("âœ… Training complete!")
print(f"Model available at: https://huggingface.co/myusername/qwen-capybara-sft")
```

**æäº¤:**

```python
hf_jobs("uv", {
    "script": "production_train.py",
    "flavor": "a10g-large",
    "timeout": "6h",
    "secrets": {"HF_TOKEN": "$HF_TOKEN"}
})
```

## å…³é”®è¦ç‚¹

**å¦‚æœæ²¡æœ‰ `push_to_hub=True` å’Œ `secrets={"HF_TOKEN": "$HF_TOKEN"}`,æ‰€æœ‰è®­ç»ƒç»“æœå°†æ°¸ä¹…ä¸¢å¤±ã€‚**

æäº¤ä»»ä½•è®­ç»ƒä½œä¸šä¹‹å‰,è¯·å§‹ç»ˆéªŒè¯ä¸¤è€…éƒ½å·²é…ç½®ã€‚
