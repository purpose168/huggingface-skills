#!/usr/bin/env python3
"""
æ”¶é›† hf-skills ç»„ç»‡çš„å‚ä¸ç§¯åˆ†ã€‚

è·Ÿè¸ªæ‰€æœ‰ä»“åº“ï¼ˆæ¨¡å‹ã€æ•°æ®é›†ã€ç©ºé—´ï¼‰çš„ç”¨æˆ·æ´»åŠ¨å¹¶è®¡æ•°ï¼š
- æ¯ä¸ªå¼€å¯çš„è®¨è®º 1 åˆ†
- æ¯æ¡å‘è¡¨çš„è¯„è®º 1 åˆ†
- æ¯ä¸ªå¼€å¯çš„ PR 1 åˆ†
- æ¯ä¸ªæ‹¥æœ‰/åˆ›å»ºçš„ä»“åº“ 1 åˆ†

ç»“æœå°†ä¿å­˜åˆ°é»‘å®¢æ’è¡Œæ¦œçš„æ•°æ®é›†ã€‚

ä½¿ç”¨æ–¹æ³•:
    HF_TOKEN=$HF_TOKEN python collect_points.py [--push-to-hub]
"""

from __future__ import annotations

import argparse
import json
import os
from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import Any

import requests

API_BASE = "https://huggingface.co/api"
ORG_NAME = "hf-skills"
USER_AGENT = "hf-skills-leaderboard/1.0"
DISCUSSION_LIMIT = 100  # Max discussions to fetch per repo
TRENDING_LIMIT = 50  # Number of trending repos to scan for external PRs


@dataclass
class UserStats:
    """è·Ÿè¸ªå•ä¸ªç”¨æˆ·çš„å‚ä¸ç»Ÿè®¡æ•°æ®ã€‚"""

    username: str
    is_org_member: bool = True
    discussions_opened: int = 0
    comments_made: int = 0
    prs_opened: int = 0
    repos_owned: int = 0
    activities: list[dict[str, Any]] = field(default_factory=list)

    @property
    def total_points(self) -> int:
        return self.discussions_opened + self.comments_made + self.prs_opened + self.repos_owned

    def to_dict(self) -> dict[str, Any]:
        return {
            "username": self.username,
            "is_org_member": self.is_org_member,
            "total_points": self.total_points,
            "discussions_opened": self.discussions_opened,
            "comments_made": self.comments_made,
            "prs_opened": self.prs_opened,
            "repos_owned": self.repos_owned,
        }


class PointsCollector:
    """ä» hf-skills ç»„ç»‡æ”¶é›†å‚ä¸ç§¯åˆ†ã€‚"""

    def __init__(self, token: str | None = None) -> None:
        self.token = token
        self.session = requests.Session()
        self.session.headers.update({"User-Agent": USER_AGENT})
        if token:
            self.session.headers.update({"Authorization": f"Bearer {token}"})
        self.user_stats: dict[str, UserStats] = {}
        self.logs: list[str] = []

    def log(self, message: str) -> None:
        """æ·»åŠ æ—¥å¿—æ¶ˆæ¯ã€‚"""
        print(message)
        self.logs.append(message)

    def _fetch_org_members(self) -> list[str]:
        """è·å–ç»„ç»‡çš„æ‰€æœ‰æˆå‘˜ã€‚"""
        try:
            from huggingface_hub import HfApi

            api = HfApi(token=self.token)
            members = list(api.list_organization_members(ORG_NAME))
            usernames = [m.username for m in members if m.username]
            self.log(f"ğŸ‘¥ æ‰¾åˆ° {len(usernames)} ä¸ªç»„ç»‡æˆå‘˜")
            return usernames
        except Exception as e:
            self.log(f"âš ï¸ è·å–ç»„ç»‡æˆå‘˜å¤±è´¥: {e}")
            # å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥å°è¯•API
            try:
                url = f"{API_BASE}/organizations/{ORG_NAME}/members"
                response = self.session.get(url, timeout=30)
                response.raise_for_status()
                members = response.json()
                usernames = [m.get("user") or m.get("username") or m.get("name") for m in members]
                usernames = [u for u in usernames if u]
                self.log(f"ğŸ‘¥ æ‰¾åˆ° {len(usernames)} ä¸ªç»„ç»‡æˆå‘˜ (é€šè¿‡API)")
                return usernames
            except Exception as e2:
                self.log(f"âš ï¸ å¤‡ç”¨æ–¹æ¡ˆä¹Ÿå¤±è´¥: {e2}")
                return []

    def collect_all(self) -> dict[str, UserStats]:
        """ä»ç»„ç»‡ä¸­çš„æ‰€æœ‰ä»“åº“æ”¶é›†ç§¯åˆ†ã€‚"""
        self.log(f"ğŸ” æ‰«æç»„ç»‡: {ORG_NAME}")

        # é¦–å…ˆï¼Œè·å–æ‰€æœ‰ç»„ç»‡æˆå‘˜å¹¶åˆå§‹åŒ–ä»–ä»¬çš„ç»Ÿè®¡æ•°æ®
        members = self._fetch_org_members()
        for username in members:
            self.user_stats[username] = UserStats(username=username)

        # ä»æ‰€æœ‰ä»“åº“ç±»å‹æ”¶é›†
        models = self._list_repos("models")
        datasets = self._list_repos("datasets")
        spaces = self._list_repos("spaces")

        all_repos = [
            *[(r, "model") for r in models],
            *[(r, "dataset") for r in datasets],
            *[(r, "space") for r in spaces],
        ]

        self.log(f"ğŸ“¦ æ‰¾åˆ° {len(models)} ä¸ªæ¨¡å‹, {len(datasets)} ä¸ªæ•°æ®é›†, {len(spaces)} ä¸ªç©ºé—´")

        for repo_info, repo_type in all_repos:
            repo_id = repo_info.get("id") or repo_info.get("modelId")
            if not repo_id:
                continue

            # ä¸ºä»“åº“æ‰€æœ‰è€…åŠ åˆ†
            owner = repo_info.get("author") or repo_id.split("/")[0]
            if owner and owner != ORG_NAME:
                self._add_point(owner, "repos_owned", repo_id, "repo_created")

            # æ‰«æè®¨è®º
            self._scan_discussions(repo_id, repo_type)

        return dict(self.user_stats)

    def scan_external_repos(self, repo_types: list[str] | None = None) -> None:
        """æ‰«ææ•´ä¸ª Hub ä¸Šçš„çƒ­é—¨ä»“åº“ï¼ŒæŸ¥æ‰¾ç»„ç»‡æˆå‘˜çš„ PRã€‚

        å‚æ•°:
            repo_types: è¦æ‰«æçš„ä»“åº“ç±»å‹åˆ—è¡¨ã€‚é€‰é¡¹ï¼š"models"ã€"datasets"ã€"spaces"ã€‚
                       å¦‚æœä¸º Noneï¼Œåˆ™æ‰«ææ‰€æœ‰ç±»å‹ã€‚
        """
        org_members = set(self.user_stats.keys())
        if not org_members:
            self.log("âš ï¸ æœªåŠ è½½ç»„ç»‡æˆå‘˜ã€‚è¯·å…ˆè¿è¡Œ collect_all()ã€‚")
            return

        if repo_types is None:
            repo_types = ["models", "datasets", "spaces"]

        self.log(f"ğŸŒ æ‰«æçƒ­é—¨ä»“åº“ï¼ŒæŸ¥æ‰¾ {len(org_members)} ä¸ªç»„ç»‡æˆå‘˜çš„ PR...")
        self.log(f"ğŸ“‚ ä»“åº“ç±»å‹: {', '.join(repo_types)}")

        for repo_type in repo_types:
            trending = self._fetch_trending(repo_type)
            self.log(f"ğŸ“ˆ æ‰«æ {len(trending)} ä¸ªçƒ­é—¨ {repo_type}...")

            for repo_info in trending:
                repo_id = repo_info.get("id") or repo_info.get("modelId")
                if not repo_id:
                    continue

                # è·³è¿‡ç»„ç»‡ä»“åº“ï¼ˆå·²æ‰«æï¼‰
                if repo_id.startswith(f"{ORG_NAME}/"):
                    continue

                # ä½¿ç”¨ä½œè€…è¿‡æ»¤å™¨æ‰«ææ¯ä¸ªç»„ç»‡æˆå‘˜çš„ PR/è®¨è®º
                self._scan_repo_for_members(repo_id, repo_type, org_members)

    def _fetch_trending(self, repo_type: str) -> list[dict[str, Any]]:
        """è·å–ç»™å®šç±»å‹çš„çƒ­é—¨ä»“åº“ã€‚"""
        endpoint = f"{API_BASE}/{repo_type}"
        params = {"sort": "trendingScore", "limit": TRENDING_LIMIT}

        try:
            response = self.session.get(endpoint, params=params, timeout=30)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            self.log(f"âš ï¸ è·å–çƒ­é—¨ {repo_type} å¤±è´¥: {e}")
            return []

    def _scan_repo_for_members(self, repo_id: str, repo_type: str, org_members: set[str]) -> None:
        """ä½¿ç”¨ä½œè€…è¿‡æ»¤å™¨æ‰«æä»“åº“çš„è®¨è®ºï¼ŒæŸ¥æ‰¾ç»„ç»‡æˆå‘˜çš„æ´»åŠ¨ã€‚"""
        # ä» repo_id è§£æå‘½åç©ºé—´å’Œä»“åº“å
        parts = repo_id.split("/")
        if len(parts) != 2:
            return
        namespace, repo = parts

        for member in org_members:
            # ä½¿ç”¨ä½œè€…è¿‡æ»¤å™¨è¿›è¡Œé«˜æ•ˆæŸ¥è¯¢
            self._fetch_member_discussions(
                repo_type=repo_type,
                namespace=namespace,
                repo=repo,
                author=member,
                discussion_type="pull_request",
            )
            self._fetch_member_discussions(
                repo_type=repo_type,
                namespace=namespace,
                repo=repo,
                author=member,
                discussion_type="discussion",
            )

    def _fetch_member_discussions(
        self,
        repo_type: str,
        namespace: str,
        repo: str,
        author: str,
        discussion_type: str = "all",
    ) -> None:
        """è·å–ç‰¹å®šä½œè€…åœ¨ä»“åº“ä¸­çš„è®¨è®ºã€‚

        ä½¿ç”¨: GET /api/{repoType}/{namespace}/{repo}/discussions?author={author}&type={type}
        """
        url = f"{API_BASE}/{repo_type}/{namespace}/{repo}/discussions"
        params = {
            "author": author,
            "type": discussion_type,
            "status": "all",
        }

        try:
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            data = response.json()
        except requests.RequestException:
            return

        discussions = data.get("discussions", [])
        repo_id = f"{namespace}/{repo}"

        for discussion in discussions:
            is_pr = discussion.get("isPullRequest", False)
            disc_num = discussion.get("num")

            if is_pr:
                self._add_point(author, "prs_opened", repo_id, "external_pr", disc_num)
                self.log(f"ğŸ”€ æ‰¾åˆ° {author} åœ¨ {repo_id} ä¸Šçš„ PR")
            else:
                self._add_point(author, "discussions_opened", repo_id, "external_discussion", disc_num)
                self.log(f"ğŸ’¬ æ‰¾åˆ° {author} åœ¨ {repo_id} ä¸Šçš„è®¨è®º")

            # è®¡ç®—è®¨è®ºä¸­çš„è¯„è®ºæ•°
            num_comments = discussion.get("numComments", 0)
            if num_comments > 0:
                self._fetch_discussion_comments(repo_type, namespace, repo, disc_num, author)

    def _fetch_discussion_comments(
        self,
        repo_type: str,
        namespace: str,
        repo: str,
        disc_num: int,
        target_author: str,
    ) -> None:
        """è·å–è®¨è®ºçš„è¯„è®ºå¹¶è®¡ç®—ç›®æ ‡ä½œè€…çš„è¯„è®ºæ•°ã€‚"""
        url = f"{API_BASE}/{repo_type}/{namespace}/{repo}/discussions/{disc_num}"

        try:
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            data = response.json()
        except requests.RequestException:
            return

        repo_id = f"{namespace}/{repo}"
        events = data.get("events", [])
        for event in events:
            if event.get("type") == "comment":
                author_info = event.get("author", {}) or {}
                author = author_info.get("name") or author_info.get("fullname")
                if author == target_author:
                    self._add_point(author, "comments_made", repo_id, "external_comment", disc_num)

    def _list_repos(self, repo_type: str) -> list[dict[str, Any]]:
        """åˆ—å‡ºç»„ç»‡ä¸­ç»™å®šç±»å‹çš„æ‰€æœ‰ä»“åº“ã€‚"""
        endpoint = f"{API_BASE}/{repo_type}"
        params = {"author": ORG_NAME, "limit": 1000}

        try:
            response = self.session.get(endpoint, params=params, timeout=30)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            self.log(f"âš ï¸ åˆ—å‡º {repo_type} å¤±è´¥: {e}")
            return []

    def _scan_discussions(self, repo_id: str, repo_type: str) -> None:
        """æ‰«æä»“åº“çš„æ‰€æœ‰è®¨è®ºå¹¶è®¡ç®—å‚ä¸åº¦ã€‚"""
        # æ˜ å°„ä»“åº“ç±»å‹åˆ° API è·¯å¾„
        type_map = {"model": "models", "dataset": "datasets", "space": "spaces"}
        api_type = type_map.get(repo_type, "models")

        url = f"{API_BASE}/{api_type}/{repo_id}/discussions"

        try:
            response = self.session.get(url, params={"limit": DISCUSSION_LIMIT}, timeout=30)
            response.raise_for_status()
            data = response.json()
        except requests.RequestException as e:
            self.log(f"âš ï¸ è·å– {repo_id} çš„è®¨è®ºå¤±è´¥: {e}")
            return

        discussions = data.get("discussions", [])
        if not discussions:
            return

        self.log(f"ğŸ’¬ {repo_id}: æ‰¾åˆ° {len(discussions)} ä¸ªè®¨è®º")

        for discussion in discussions:
            self._process_discussion(repo_id, api_type, discussion)

    def _process_discussion(self, repo_id: str, api_type: str, discussion: dict[str, Any]) -> None:
        """å¤„ç†å•ä¸ªè®¨è®ºåŠå…¶è¯„è®ºã€‚"""
        author_info = discussion.get("author", {}) or {}
        author = author_info.get("name") or author_info.get("fullname")
        is_pr = discussion.get("isPullRequest", False)
        disc_num = discussion.get("num")

        if author and author != ORG_NAME:
            activity_type = "pr_opened" if is_pr else "discussion_opened"
            point_type = "prs_opened" if is_pr else "discussions_opened"
            self._add_point(author, point_type, repo_id, activity_type, disc_num)

        # è·å–è®¨è®ºè¯¦æƒ…ä»¥è·å–è¯„è®º
        if disc_num:
            self._fetch_comments(repo_id, api_type, disc_num)

    def _fetch_comments(self, repo_id: str, api_type: str, disc_num: int) -> None:
        """è·å–å¹¶è®¡ç®—è®¨è®ºçš„è¯„è®ºæ•°ã€‚"""
        url = f"{API_BASE}/{api_type}/{repo_id}/discussions/{disc_num}"

        try:
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            data = response.json()
        except requests.RequestException:
            # é™é»˜è·³è¿‡å¤±è´¥çš„è¯„è®ºè·å–
            return

        events = data.get("events", [])
        for event in events:
            event_type = event.get("type")
            # è®¡ç®—è¯„è®ºï¼ˆä¸æ˜¯åˆå§‹å¸–å­ã€çŠ¶æ€å˜æ›´ç­‰ï¼‰
            if event_type == "comment":
                author_info = event.get("author", {}) or {}
                author = author_info.get("name") or author_info.get("fullname")
                if author and author != ORG_NAME:
                    self._add_point(author, "comments_made", repo_id, "comment", disc_num)

    def _add_point(
        self,
        username: str,
        point_type: str,
        repo_id: str,
        activity_type: str,
        disc_num: int | None = None,
    ) -> None:
        """ä¸ºç”¨æˆ·çš„ç»Ÿè®¡æ•°æ®æ·»åŠ ç§¯åˆ†ã€‚"""
        if not username:
            return

        # ä¸ºä¸åœ¨ç»„ç»‡ä¸­çš„ç”¨æˆ·ï¼ˆå¤–éƒ¨è´¡çŒ®è€…ï¼‰åˆå§‹åŒ–ç»Ÿè®¡æ•°æ®
        if username not in self.user_stats:
            self.user_stats[username] = UserStats(username=username, is_org_member=False)

        stats = self.user_stats[username]
        current = getattr(stats, point_type, 0)
        setattr(stats, point_type, current + 1)

        stats.activities.append(
            {
                "type": activity_type,
                "repo_id": repo_id,
                "discussion_num": disc_num,
                "timestamp": datetime.now(timezone.utc).isoformat(),
            }
        )

    def get_leaderboard(self) -> list[dict[str, Any]]:
        """è·å–æŒ‰æ€»ç§¯åˆ†æ’åºçš„æ’è¡Œæ¦œã€‚"""
        leaderboard = [stats.to_dict() for stats in self.user_stats.values()]
        leaderboard.sort(key=lambda x: x["total_points"], reverse=True)
        return leaderboard

    def save_json(self, filepath: str) -> None:
        """å°†æ’è¡Œæ¦œä¿å­˜åˆ°JSONæ–‡ä»¶ã€‚"""
        leaderboard = self.get_leaderboard()
        output = {
            "generated_at": datetime.now(timezone.utc).isoformat(),
            "organization": ORG_NAME,
            "total_participants": len(leaderboard),
            "leaderboard": leaderboard,
        }
        with open(filepath, "w") as f:
            json.dump(output, f, indent=2)
        self.log(f"ğŸ’¾ å·²ä¿å­˜æ’è¡Œæ¦œåˆ° {filepath}")

    def push_to_hub(self, repo_id: str = "hf-skills/hackers-leaderboard") -> None:
        """å°†æ’è¡Œæ¦œæ•°æ®æ¨é€åˆ°HFæ•°æ®é›†ã€‚"""
        try:
            from huggingface_hub import HfApi
        except ImportError:
            self.log("âŒ huggingface_hub æœªå®‰è£…ã€‚è¿è¡Œï¼špip install huggingface_hub")
            return

        api = HfApi()
        leaderboard = self.get_leaderboard()

        # åˆ›å»ºJSONLæ ¼å¼æ•°æ®é›†
        jsonl_content = "\n".join(json.dumps(row) for row in leaderboard)

        # åŒæ—¶åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶
        metadata = {
            "generated_at": datetime.now(timezone.utc).isoformat(),
            "organization": ORG_NAME,
            "total_participants": len(leaderboard),
            "total_points": sum(row["total_points"] for row in leaderboard),
        }

        try:
            # å¦‚æœä»“åº“ä¸å­˜åœ¨åˆ™åˆ›å»º
            api.create_repo(repo_id=repo_id, repo_type="dataset", exist_ok=True)
            self.log(f"ğŸ“ ç¡®ä¿æ•°æ®é›†ä»“åº“å­˜åœ¨ï¼š{repo_id}")

            # ä¸Šä¼ æ’è¡Œæ¦œæ•°æ®
            api.upload_file(
                path_or_fileobj=jsonl_content.encode(),
                path_in_repo="data/leaderboard.jsonl",
                repo_id=repo_id,
                repo_type="dataset",
                commit_message=f"Update leaderboard - {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M')} UTC",
            )

            # ä¸Šä¼ å…ƒæ•°æ®
            api.upload_file(
                path_or_fileobj=json.dumps(metadata, indent=2).encode(),
                path_in_repo="data/metadata.json",
                repo_id=repo_id,
                repo_type="dataset",
                commit_message=f"Update metadata - {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M')} UTC",
            )

            self.log(f"ğŸš€ å·²å°†æ’è¡Œæ¦œæ¨é€åˆ° {repo_id}")
        except Exception as e:
            self.log(f"âŒ æ¨é€åˆ°hubå¤±è´¥ï¼š{e}")


def main() -> None:
    parser = argparse.ArgumentParser(description="ä» hf-skills ç»„ç»‡æ”¶é›†å‚ä¸ç§¯åˆ†")
    parser.add_argument(
        "--push-to-hub",
        action="store_true",
        help="å°†ç»“æœæ¨é€åˆ° HF æ•°æ®é›†",
    )
    parser.add_argument(
        "--output",
        type=str,
        default="leaderboard.json",
        help="è¾“å‡º JSON æ–‡ä»¶è·¯å¾„",
    )
    parser.add_argument(
        "--repo-id",
        type=str,
        default="hf-skills/hackers-leaderboard",
        help="ç”¨äºæ¨é€çš„ HF æ•°æ®é›†ä»“åº“ ID",
    )
    parser.add_argument(
        "--scan-external",
        action="store_true",
        help="åŒæ—¶æ‰«æçƒ­é—¨ä»“åº“ä»¥è·å–ç»„ç»‡æˆå‘˜çš„ PR/è®¨è®º",
    )
    parser.add_argument(
        "--repo-type",
        type=str,
        nargs="+",
        choices=["models", "datasets", "spaces"],
        default=None,
        help="è¦æ‰«æçš„ä»“åº“ç±»å‹ï¼ˆç”¨äº --scan-externalï¼‰ã€‚é»˜è®¤ï¼šæ‰€æœ‰ç±»å‹",
    )
    args = parser.parse_args()

    token = os.environ.get("HF_TOKEN")
    if not token:
        print("âš ï¸ æœªæ‰¾åˆ° HF_TOKENã€‚æŸäº›è¯·æ±‚å¯èƒ½ä¼šå—åˆ°é€Ÿç‡é™åˆ¶ã€‚")

    collector = PointsCollector(token=token)
    collector.collect_all()

    # å¯é€‰ï¼šæ‰«æå¤–éƒ¨ä»“åº“ä»¥è·å–æˆå‘˜æ´»åŠ¨
    if args.scan_external:
        collector.scan_external_repos(repo_types=args.repo_type)

    # æ‰“å°æ’è¡Œæ¦œ
    print("\n" + "=" * 50)
    print("ğŸ† é»‘å®¢æ’è¡Œæ¦œ")
    print("=" * 50)

    leaderboard = collector.get_leaderboard()
    for i, entry in enumerate(leaderboard[:20], 1):
        print(
            f"{i:2}. {entry['username']:20} - {entry['total_points']:4} åˆ† "
            f"(ğŸ’¬{entry['discussions_opened']} ğŸ“{entry['comments_made']} "
            f"ğŸ”€{entry['prs_opened']} ğŸ“¦{entry['repos_owned']})"
        )

    if len(leaderboard) > 20:
        print(f"   ... è¿˜æœ‰ {len(leaderboard) - 20} ä¸ªå‚ä¸è€…")

    print("=" * 50)
    print(f"æ€»å‚ä¸è€…æ•°: {len(leaderboard)}")
    print(f"å·²é¢å‘æ€»ç§¯åˆ†: {sum(e['total_points'] for e in leaderboard)}")

    # ä¿å­˜åˆ°æœ¬åœ°
    collector.save_json(args.output)

    # å¦‚æœè¯·æ±‚ï¼Œæ¨é€åˆ° hub
    if args.push_to_hub:
        collector.push_to_hub(args.repo_id)


if __name__ == "__main__":
    main()
